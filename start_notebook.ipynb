{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robofish Restart\n",
    "\n",
    "This is a restart of the robofish codebase starting from scratch with a focused goal of \n",
    "8+8 -> 1+16 channel input output\n",
    "\n",
    "The implementation process will be\n",
    "\n",
    "1. Create Dataset\n",
    "2. Create Model\n",
    "3. Define loss functions\n",
    "4. Define train loop\n",
    "5. Visualise history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import skimage.io as skio\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load took : 0.02535223960876465 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_data_dir = './Data/50'\n",
    "\n",
    "ds_type = ['train','test','val']\n",
    "\n",
    "class sim_ds(Dataset):\n",
    "\n",
    "    def __init__(self,root_data_dir = root_data_dir, ds_type = 'train',ir_num = 16,ntiles=500,transforms=None):\n",
    "        \n",
    "\n",
    "        data_dir = path.join(root_data_dir,ds_type,'1')\n",
    "\n",
    "        self.data_dir647 = path.join(data_dir,'647nm, Raw')\n",
    "        self.data_dir750 = path.join(data_dir,'750nm, Raw')\n",
    "        \n",
    "        self.irs = [i for i in range(ir_num)]\n",
    "        self.fovs = [i for i in range(ntiles)]\n",
    "\n",
    "        self.gt = path.join(data_dir,'groundtruths')\n",
    "        \n",
    "        self.img_format = 'merFISH_{:02d}_{:03d}_01.TIFF'\n",
    "        self.freq_format = 'frequency_{}.csv'\n",
    "        self.loc_format = 'groundtruth_{}.csv'\n",
    "        #get imagesize\n",
    "\n",
    "        with open(path.join(data_dir,'config.yml')) as file:\n",
    "            self.params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "        self.img_size = self.params['simulation']['image_size']\n",
    "        self.ds_size = self.params['simulation']['tile_count']\n",
    "        self.emitters = self.params['simulation']['emitter_count']\n",
    "        self.non_emitters = self.img_size**2 - self.params['simulation']['emitter_count']\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ds_size\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        # Create the targets\n",
    "        bc_mat = torch.zeros((len(self.irs),self.img_size,self.img_size),requires_grad=False)\n",
    "        loc_mat = torch.zeros((1,self.img_size,self.img_size),requires_grad=False)\n",
    "        \n",
    "        gt_file = pd.read_csv(path.join(self.gt,self.loc_format).format(idx+1))\n",
    "        \n",
    "        rows = gt_file['row'].tolist()\n",
    "        \n",
    "        columns = gt_file['column'].tolist()\n",
    "        \n",
    "        loc_mat[len(rows)*[0],\n",
    "                rows,\n",
    "                columns,\n",
    "                ]=1.\n",
    "\n",
    "        bcs = gt_file['barcode'].tolist()\n",
    "\n",
    "        for ibc,bc in enumerate(bcs):\n",
    "            bc = bc[1:-1]\n",
    "            _bc = [int(s) for s in bc]\n",
    "            \n",
    "            c_list = [i*s for i,s in zip(range(len(self.irs)),_bc)]\n",
    "\n",
    "            bc_mat[c_list,rows[ibc],columns[ibc]] = 1.\n",
    "        \n",
    "        #extract the data\n",
    "\n",
    "        ir_idxs = len(self.irs)//2\n",
    "        \n",
    "        x647s = torch.zeros((ir_idxs,self.img_size,self.img_size),dtype=float)\n",
    "        x750s = torch.zeros((ir_idxs,self.img_size,self.img_size),dtype=float)\n",
    "        \n",
    "        for i in range(1,ir_idxs+1):\n",
    "            x647s[i-1,:,:] = torch.from_numpy(\n",
    "                skio.imread(path.join(self.data_dir647,self.img_format).format(i,idx+1)).astype(float)[:,:,0]\n",
    "                )\n",
    "            x750s[i-1,:,:] = torch.from_numpy(skio.imread(path.join(self.data_dir750,self.img_format).format(i,idx+1)).astype(float)\n",
    "            [:,:,0])\n",
    "        \n",
    "\n",
    "        if not (self.transforms is None):\n",
    "            x647s = self.transforms(x647s)\n",
    "            x750s = self.transforms(x750s)\n",
    "\n",
    "        return x647s,x750s,loc_mat,bc_mat\n",
    "\n",
    "\n",
    "ds = sim_ds()\n",
    "start = time.time()\n",
    "x647s,x750s,loc_mat,bc_mat = next(iter(ds))\n",
    "duration = time.time()-start\n",
    "\n",
    "print('load took : {} ms'.format(duration))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Model\n",
    "\n",
    "\n",
    "1. Create the downsample stage\n",
    "\n",
    "2. Create the upsample stage\n",
    "\n",
    "3. make a Unet\n",
    "\n",
    "4. make a multistage unet\n",
    "\n",
    "5. make the final output layers\n",
    "\n",
    "6. pacakge it all up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class downsampleStage(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels=None):\n",
    "\n",
    "        super(downsampleStage,self).__init__()\n",
    "        if out_channels is None:\n",
    "            out_channels = 2*in_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                out_channels=out_channels,\n",
    "                                kernel_size=3,\n",
    "                                padding = 1,\n",
    "                                padding_mode='reflect')\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels,\n",
    "                                out_channels=out_channels,\n",
    "                                kernel_size=3,\n",
    "                                padding = 1,\n",
    "                                padding_mode='reflect')\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channels,\n",
    "                                out_channels=out_channels,\n",
    "                                kernel_size=3,\n",
    "                                padding = 1,\n",
    "                                padding_mode='reflect')\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = F.elu(self.conv3(x))\n",
    "        skip = x\n",
    "        x = self.pool(x)\n",
    "\n",
    "        return x,skip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class upsampleStage(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels = None,last_channel_out=None):\n",
    "\n",
    "        super(upsampleStage,self).__init__()\n",
    "        if out_channels is None:\n",
    "            out_channels=int(in_channels//2)\n",
    "        if last_channel_out is None:\n",
    "            last_channel_out=out_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                out_channels=out_channels,\n",
    "                                kernel_size=3,\n",
    "                                padding = 1,\n",
    "                                padding_mode='reflect')\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels,\n",
    "                                out_channels=out_channels,\n",
    "                                kernel_size=3,\n",
    "                                padding = 1,\n",
    "                                padding_mode='reflect')\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channels,\n",
    "                                out_channels=last_channel_out,\n",
    "                                kernel_size=3,\n",
    "                                padding = 1,\n",
    "                                padding_mode='reflect')\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=(2,2),mode='nearest')\n",
    "\n",
    "    def forward(self,x,skip):\n",
    "        x = F.interpolate(x,scale_factor=2)\n",
    "        x = torch.concat((x,skip),dim=1)\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = F.elu(self.conv3(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleneck(nn.Module):\n",
    "    def __init__(self,in_channels=96,out_channels=192):\n",
    "        super(bottleneck,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                out_channels=out_channels,\n",
    "                                kernel_size=3,\n",
    "                                padding=1,\n",
    "                                padding_mode='reflect',\n",
    "                                )\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels,\n",
    "                                out_channels=out_channels,\n",
    "                                kernel_size=3,\n",
    "                                padding=1,\n",
    "                                padding_mode='reflect',\n",
    "                                )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 0.06132817268371582 ms\n",
      "torch.Size([1, 8, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "class unet(nn.Module):\n",
    "    def __init__(self,in_channels,last_out_channels=1):\n",
    "        super(unet,self).__init__()\n",
    "        \n",
    "        self.add_module('down1',downsampleStage(in_channels,48))\n",
    "        self.add_module('down2',downsampleStage(48,96))\n",
    "        \n",
    "        self.add_module('bottleneck',bottleneck(96,192))\n",
    "\n",
    "        self.add_module('up1',upsampleStage(192+96,96))\n",
    "        self.add_module('up2',upsampleStage(96+48,48,last_out_channels))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x,skipx1 = self.down1(x)\n",
    "        x,skipx2 = self.down2(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.up1(x,skipx2)\n",
    "        x = self.up2(x,skipx1)\n",
    "        return x\n",
    "\n",
    "        \n",
    "\n",
    "model = unet(8,8)\n",
    "test_input = torch.rand((1,8,40,40))\n",
    "start = time.time()\n",
    "out = model(test_input)\n",
    "duration = time.time()-start\n",
    "print('duration: {} ms'.format(duration))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 0.5348851680755615 ms\n",
      "torch.Size([1, 48, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "class multiStage(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels=8,last_out_first_stage=1):\n",
    "        super(multiStage,self).__init__()\n",
    "\n",
    "        stage647 = unet(in_channels,last_out_first_stage)\n",
    "        stage750 = unet(in_channels,last_out_first_stage)\n",
    "        self.add_module('first_stage_647',stage647)\n",
    "        self.add_module('first_stage_750',stage750)\n",
    "\n",
    "        stage2 = unet(last_out_first_stage+last_out_first_stage,48)\n",
    "        self.add_module('second_stage',stage2)\n",
    "\n",
    "    def forward(self,x647,x750):\n",
    "        x1 = self.first_stage_647(x647)\n",
    "        x2 = self.first_stage_647(x750)\n",
    "\n",
    "        x = torch.cat((x1,x2),dim=1)\n",
    "\n",
    "        y = self.second_stage(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "model = multiStage(8,1)\n",
    "test_input647 = torch.rand((1,8,40,40))\n",
    "test_input750 = torch.rand((1,8,40,40))\n",
    "\n",
    "start = time.time()\n",
    "out = model(test_input647,test_input750)\n",
    "duration = time.time()-start\n",
    "print('duration: {} ms'.format(duration))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 0.21235108375549316 ms\n",
      "torch.Size([1, 1, 40, 40])\n",
      "torch.Size([1, 16, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "class anglerFISH(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels=8,first_stage_channels=8):\n",
    "        super(anglerFISH,self).__init__()\n",
    "        self.add_module('twostage',multiStage(in_channels,first_stage_channels))\n",
    "        \n",
    "        self.add_module('head_p', nn.Sequential(nn.Conv2d(in_channels = 48,\n",
    "                                                            out_channels = 48,\n",
    "                                                            kernel_size=3,\n",
    "                                                            padding=1,\n",
    "                                                            padding_mode='reflect')\n",
    "                                                            ,\n",
    "                                            nn.Conv2d(in_channels = 48,\n",
    "                                                            out_channels = 1,\n",
    "                                                            kernel_size=3,\n",
    "                                                            padding=1,\n",
    "                                                            padding_mode='reflect')\n",
    "                                                ))\n",
    "                                            \n",
    "\n",
    "        self.add_module('head_bc',nn.Sequential(nn.Conv2d(in_channels = 48,\n",
    "                                                            out_channels = 48,\n",
    "                                                            kernel_size=3,\n",
    "                                                            padding=1,\n",
    "                                                            padding_mode='reflect')\n",
    "                                                            ,\n",
    "                                            nn.Conv2d(in_channels = 48,\n",
    "                                                            out_channels = 16,\n",
    "                                                            kernel_size=3,\n",
    "                                                            padding=1,\n",
    "                                                            padding_mode='reflect')\n",
    "                                                ))\n",
    "    def forward(self,x647,x750):\n",
    "\n",
    "        x = self.twostage(x647,x750)\n",
    "        out_p = torch.sigmoid(self.head_p(x))\n",
    "        out_bc = torch.sigmoid(self.head_bc(x))\n",
    "\n",
    "        return out_p,out_bc\n",
    "\n",
    "            \n",
    "\n",
    "model = anglerFISH(8,1)\n",
    "test_input647 = torch.rand((1,8,40,40))\n",
    "test_input750 = torch.rand((1,8,40,40))\n",
    "\n",
    "start = time.time()\n",
    "out_p,out_bc = model(test_input647,test_input750)\n",
    "duration = time.time()-start\n",
    "print('duration: {} ms'.format(duration))\n",
    "print(out_p.shape)        \n",
    "print(out_bc.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the Loss Functions\n",
    "\n",
    "1. Probability loss\n",
    "2. Barcode loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 0.2881779670715332 ms\n",
      "Prediction Loss: 0.7066015005111694\n",
      "BC Loss: 1.7378418445587158\n"
     ]
    }
   ],
   "source": [
    "def prob_loss(pred,target):\n",
    "\n",
    "    return F.binary_cross_entropy(pred,target,reduction='mean')\n",
    "\n",
    "\n",
    "def valid_barcode_loss(pred:torch.tensor,target:torch.tensor,weight=1,reduction=torch.mean):\n",
    "    limit = torch.tensor(16*[-100])\n",
    "    _t = weight*target * torch.maximum(torch.log(pred),limit) + (1-target)*torch.maximum(torch.log(1-pred),limit)\n",
    "    return reduction(-_t)\n",
    "\n",
    "def barcode_loss(pred:torch.tensor,target:torch.tensor,weight=ds.non_emitters/ds.emitters,valid_weight=12/4):\n",
    "\n",
    "    target = torch.permute(target,(0,2,3,1))\n",
    "    target = target.reshape(-1,16)\n",
    "    \n",
    "\n",
    "    pred = torch.permute(pred,(0,2,3,1))\n",
    "    pred = pred.reshape(-1,16)\n",
    "\n",
    "    flags = target.sum(dim=1)>0\n",
    "    loss = torch.tensor(0.)\n",
    "    for i in range(pred.shape[0]):\n",
    " \n",
    "        loss += weight*flags[i]*valid_barcode_loss(pred[i],target[i],valid_weight) + (1-1*flags[i])*F.binary_cross_entropy(pred[i],target[i],reduction='mean')\n",
    "    loss /=pred.shape[0] \n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "model = anglerFISH(8,1).float()\n",
    "x647s,x750s,loc_mat,bc_mat = next(iter(ds))\n",
    "\n",
    "start = time.time()\n",
    "out_p,out_bc = model(x647s.unsqueeze(0).float(),x750s.unsqueeze(0).float())\n",
    "duration = time.time()-start\n",
    "print('duration: {} ms'.format(duration))\n",
    "print('Prediction Loss: {}'.format(prob_loss(out_p,loc_mat.unsqueeze(0).float())))\n",
    "print('BC Loss: {}'.format(barcode_loss(out_bc,bc_mat.unsqueeze(0).float())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Training loop\n",
    "\n",
    "Set the optimizer and the loss functions and define a train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_fn = optim.AdamW(model.parameters(),lr=1e-4)\n",
    "\n",
    "train_ds = sim_ds(ds_type='train',ntiles=50)\n",
    "test_ds = sim_ds(ds_type='test',ntiles=50)\n",
    "val_ds = sim_ds(ds_type='val',ntiles=50)\n",
    "\n",
    "train_dl = DataLoader(train_ds,batch_size=2,shuffle=True)\n",
    "test_dl = DataLoader(test_ds,batch_size=1,shuffle=True)\n",
    "val_dl = DataLoader(val_ds,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10/250 [00:12<04:52,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Avg Running Loss per sample: 1.177322506904602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20/250 [00:24<04:35,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Avg Running Loss per sample: 1.0449921011924743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 30/250 [00:37<04:49,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Avg Running Loss per sample: 0.9761187930901846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 40/250 [00:50<04:26,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Avg Running Loss per sample: 0.9396027356386185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 50/250 [01:03<04:16,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Avg Running Loss per sample: 0.9170884239673615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 51/250 [01:06<04:18,  1.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/shahidhaider/Code/robofish-restart/start_notebook.ipynb Cell 16'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shahidhaider/Code/robofish-restart/start_notebook.ipynb#ch0000019?line=23'>24</a>\u001b[0m         loss_history\u001b[39m.\u001b[39mappend(epoch_loss\u001b[39m/\u001b[39mdenom)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shahidhaider/Code/robofish-restart/start_notebook.ipynb#ch0000019?line=26'>27</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_history\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/shahidhaider/Code/robofish-restart/start_notebook.ipynb#ch0000019?line=29'>30</a>\u001b[0m train()\n",
      "\u001b[1;32m/Users/shahidhaider/Code/robofish-restart/start_notebook.ipynb Cell 16'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, print_rate, dataset, dataloader, optimizer_fn)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shahidhaider/Code/robofish-restart/start_notebook.ipynb#ch0000019?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m barcode_loss(out_bc,bc_mat,dataset\u001b[39m.\u001b[39mnon_emitters\u001b[39m/\u001b[39mdataset\u001b[39m.\u001b[39memitters,\u001b[39m12\u001b[39m\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m) \u001b[39m+\u001b[39m prob_loss(out_p,loc_mat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shahidhaider/Code/robofish-restart/start_notebook.ipynb#ch0000019?line=14'>15</a>\u001b[0m \u001b[39m#print(loss)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/shahidhaider/Code/robofish-restart/start_notebook.ipynb#ch0000019?line=15'>16</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shahidhaider/Code/robofish-restart/start_notebook.ipynb#ch0000019?line=16'>17</a>\u001b[0m optimizer_fn\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shahidhaider/Code/robofish-restart/start_notebook.ipynb#ch0000019?line=17'>18</a>\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/nn/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(model = model,epochs=2,print_rate=10,dataset=train_ds,dataloader=train_dl,optimizer_fn=optimizer_fn):\n",
    "    loss_history =list()\n",
    "    for e in range(epochs):\n",
    "        count = 0\n",
    "        epoch_loss= 0\n",
    "        for x647s,x750s,loc_mat,bc_mat in tqdm(dataloader):\n",
    "            count+=1\n",
    "            optimizer_fn.zero_grad()\n",
    "            out_p,out_bc = model(x647s.float(),x750s.float())\n",
    "            if torch.any(torch.isnan(out_p)):\n",
    "                print('prediction is nan')\n",
    "                if torch.any(torch.isnan(x647s)) or torch.any(torch.isnan(x750s)):\n",
    "                    print('input is nan')\n",
    "            loss = barcode_loss(out_bc,bc_mat,dataset.non_emitters/dataset.emitters,12/4) + prob_loss(out_p,loc_mat)\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "            optimizer_fn.step()\n",
    "            epoch_loss +=loss.item()\n",
    "            if count % print_rate==0:\n",
    "                denom = count*x647s.shape[0]\n",
    "                print('Epoch: {} | Avg Running Loss per sample: {}'.format(e,epoch_loss/denom))\n",
    "\n",
    "        denom = count*x647s.shape[0]\n",
    "        loss_history.append(epoch_loss/denom)\n",
    "\n",
    "\n",
    "    return loss_history\n",
    "\n",
    "\n",
    "train()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x647s,x750s,loc_mat,bc_mat = next(iter(ds))\n",
    "out_p,out_bc = model(x647s.unsqueeze(0).float(),x750s.unsqueeze(0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5057, 0.5056, 0.5055,  ..., 0.5034, 0.5036, 0.5032],\n",
       "          [0.5056, 0.5056, 0.5055,  ..., 0.5031, 0.5033, 0.5029],\n",
       "          [0.5056, 0.5055, 0.5055,  ..., 0.5035, 0.5037, 0.5032],\n",
       "          ...,\n",
       "          [0.5052, 0.5051, 0.5053,  ..., 0.5054, 0.5054, 0.5053],\n",
       "          [0.5052, 0.5052, 0.5052,  ..., 0.5054, 0.5053, 0.5053],\n",
       "          [0.5050, 0.5050, 0.5051,  ..., 0.5052, 0.5052, 0.5052]]]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69298524ebcd0cf30e96b9bf40e4206b4bec8f7928d937de0acc7e0d12d6fe79"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
